from pathlib import Path

import lightning as L
import rich_click as click
from rich import print

from radionets.core.callbacks import Callbacks
from radionets.core.logging import Loggers
from radionets.io import TrainConfig
from radionets.training import TrainModule
from radionets.utils._paths import _validate_pre_model_path
from radionets.utils.codecarbon import carbontracker


@click.command()
@click.argument(
    "mode",
    type=click.Choice(["train", "test", "predict"], case_sensitive=False),
    default="train",
)
@click.argument("config_path", type=click.Path(exists=True, dir_okay=False))
@click.option("--premodel", "-p", type=click.Path(exists=True, dir_okay=False))
def main(config_path, mode="train", premodel=None):
    """Starts the radionets training process with
    options specified in configuration file.

    Parameters
    ----------
    configuration_path : str
        Path to the configuration toml file.
    mode : str, optional
        Operation mode, can be one of {'train'}.
        Default: 'train'
    """
    if not isinstance(config_path, Path):
        config_path = Path(config_path)

    train_config = TrainConfig.from_toml(config_path)

    print(train_config)

    if mode == "test":
        train_config.paths.model_path /= "testing"

    if mode == "predict":
        train_config.paths.model_path /= "inference"

    if premodel:
        # if the premodel cli option is used, overwrite config path
        train_config.paths.pre_model = premodel

    data_module = train_config.dataloader.datamodule(
        data_dir=train_config.paths.data_path,
        batch_size=train_config.hypers.batch_size,
        **train_config.dataloader.model_dump(exclude=["data_dir", "batch_size"]),
    )

    # Dumping train_config to a dict here results in nicer
    # formatting in hparams.yaml files generated by lightning
    train_module = TrainModule(train_config.model_dump())

    loggers = Loggers.get_loggers(train_config)
    callbacks = Callbacks.get_callbacks(train_config)

    # with rich_training_layout(train_config, callbacks) as layout_callbacks:
    trainer = L.Trainer(
        limit_train_batches=data_module.train_length // train_config.hypers.batch_size
        if data_module.train_length
        else train_config.hypers.batch_size,
        limit_val_batches=data_module.valid_length // train_config.hypers.batch_size
        if data_module.valid_length
        else train_config.hypers.batch_size,
        limit_test_batches=data_module.test_length // train_config.hypers.batch_size
        if data_module.test_length
        else train_config.hypers.batch_size,
        max_epochs=train_config.general.num_epochs,
        callbacks=callbacks,
        logger=loggers,
        log_every_n_steps=train_config.hypers.batch_size,
        devices=train_config.devices.num_devices,
        accelerator=train_config.devices.accelerator,
        precision=train_config.devices.precision,
        strategy=train_config.deepspeed if train_config.deepspeed else "auto",
    )

    if mode.lower() == "train":
        with carbontracker(train_config=train_config):
            trainer.fit(model=train_module, datamodule=data_module)

    elif mode.lower() == "test":
        _validate_pre_model_path(train_config)

        train_module = TrainModule.load_from_checkpoint(train_config.paths.pre_model)
        preds = trainer.test(model=train_module, datamodule=data_module)

        return preds

    elif mode.lower() == "predict":
        _validate_pre_model_path(train_config)

        train_module = TrainModule.load_from_checkpoint(train_config.paths.pre_model)
        preds = trainer.predict(model=train_module, datamodule=data_module)

        return preds


if __name__ == "__main__":
    main()
